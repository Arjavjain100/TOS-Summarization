{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5427149,"sourceType":"datasetVersion","datasetId":3140872}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import LongformerModel, LongformerTokenizer, LongformerConfig\nimport torch\nimport pandas as pd\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_file_path = \"/kaggle/input/all-v1-transpose/all_v1_transpose.csv\"  \ndf = pd.read_csv(csv_file_path)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_texts = df[\"original_text\"].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:38:11.625942Z","iopub.execute_input":"2023-12-02T15:38:11.626313Z","iopub.status.idle":"2023-12-02T15:38:11.631890Z","shell.execute_reply.started":"2023-12-02T15:38:11.626283Z","shell.execute_reply":"2023-12-02T15:38:11.630968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculte_inference(model, tokenizer, input_texts, device):\n    # INIT LOGGERS\n    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n    repetitions = 300\n    timings = np.zeros((repetitions, 1))\n\n    # GPU-WARM-UP\n    for _ in range(10):\n        for text in df[\"original_text\"]:\n            input_ids = tokenizer(text, return_tensors=\"pt\").to(device)\n            _ = model(**input_ids)\n\n    # MEASURE PERFORMANCE\n    with torch.no_grad():\n        for rep in range(repetitions):\n            starter.record()\n            for text in df[\"original_text\"]:\n                input_ids = tokenizer(text, return_tensors=\"pt\").to(device)\n                _ = model(**input_ids)\n            ender.record()\n            # WAIT FOR GPU SYNC\n            torch.cuda.synchronize()\n            curr_time = starter.elapsed_time(ender)\n            timings[rep] = curr_time\n\n    mean_syn = np.sum(timings) / repetitions\n    std_syn = np.std(timings)\n    return mean_syn, std_syn","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:38:39.295292Z","iopub.execute_input":"2023-12-02T15:38:39.296033Z","iopub.status.idle":"2023-12-02T15:38:39.304727Z","shell.execute_reply.started":"2023-12-02T15:38:39.295997Z","shell.execute_reply":"2023-12-02T15:38:39.303714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Longformer","metadata":{}},{"cell_type":"code","source":"#Longformer configuration\nconfig = LongformerConfig.from_json_file(\"/kaggle/input/config-and-models/Config and Model/Longformer_config.json\")\nmodel = LongformerModel(config)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:39:08.902437Z","iopub.execute_input":"2023-12-02T15:39:08.903191Z","iopub.status.idle":"2023-12-02T15:39:10.402571Z","shell.execute_reply.started":"2023-12-02T15:39:08.903154Z","shell.execute_reply":"2023-12-02T15:39:10.401767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learned parameters (weights)\nmodel.load_state_dict(torch.load(\"/kaggle/input/config-and-models/Config and Model/longformer_pytorch_model\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:40:11.217856Z","iopub.execute_input":"2023-12-02T15:40:11.218486Z","iopub.status.idle":"2023-12-02T15:40:11.419818Z","shell.execute_reply.started":"2023-12-02T15:40:11.218454Z","shell.execute_reply":"2023-12-02T15:40:11.418583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = LongformerTokenizer.from_pretrained(\"allenai/led-base-16384\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_time, std_time = measure_inference_time(model, tokenizer, input_texts, device)","metadata":{},"execution_count":null,"outputs":[]}]}