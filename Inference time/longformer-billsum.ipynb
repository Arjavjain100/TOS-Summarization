{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6832486,"sourceType":"datasetVersion","datasetId":3928154}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers==4.30\n!pip install accelerate -U\n!pip install sentencepiece\n!pip install rouge\n!pip install wandb onnx -Uq","metadata":{"id":"C-OBrGewb_Wu","outputId":"fb6dde92-42df-4237-f955-1f551db4c196","execution":{"iopub.status.busy":"2023-12-02T07:47:19.181627Z","iopub.execute_input":"2023-12-02T07:47:19.182371Z","iopub.status.idle":"2023-12-02T07:48:02.642411Z","shell.execute_reply.started":"2023-12-02T07:47:19.182334Z","shell.execute_reply":"2023-12-02T07:48:02.641172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LEDForConditionalGeneration, LEDTokenizer, Trainer, TrainingArguments,pipeline,PretrainedConfig\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom sklearn.model_selection import train_test_split\nfrom rouge import Rouge\nimport pandas as pd\nimport os\nimport wandb\nimport random\nimport numpy as np\nimport accelerate\n\nos.environ[\"WANDB_PROJECT\"]=\"major-one\"\nos.environ[\"WANDB_LOG_MODEL\"]=\"checkpoint\"\nos.environ[\"WANDB_WATCH\"]=\"all\"\n\n\n\n# Ensure deterministic behavior\ntorch.backends.cudnn.deterministic = True\nrandom.seed(hash(\"setting random seeds\") % 2**32 - 1)\nnp.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\ntorch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\ntorch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n\n# Device configuration\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Dataset location\nfilename = \"/kaggle/input/tos-tldr-legal/all_v1_transpose.csv\"","metadata":{"id":"7KBtpTeJbcsA","execution":{"iopub.status.busy":"2023-12-02T07:48:02.644796Z","iopub.execute_input":"2023-12-02T07:48:02.645136Z","iopub.status.idle":"2023-12-02T07:48:02.655046Z","shell.execute_reply.started":"2023-12-02T07:48:02.645104Z","shell.execute_reply":"2023-12-02T07:48:02.654205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nwandb_api = user_secrets.get_secret(\"wandb-key\") \n\nwandb.login(key=wandb_api)","metadata":{"id":"NquUD6lhfBHO","outputId":"47d4f550-2eb9-4b7a-b273-73ad2c3800d0","execution":{"iopub.status.busy":"2023-12-02T07:48:02.656071Z","iopub.execute_input":"2023-12-02T07:48:02.656328Z","iopub.status.idle":"2023-12-02T07:48:02.986314Z","shell.execute_reply.started":"2023-12-02T07:48:02.656305Z","shell.execute_reply":"2023-12-02T07:48:02.985388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(filename)\ndf.shape","metadata":{"id":"ERL_fIRDcBOB","execution":{"iopub.status.busy":"2023-12-02T07:48:02.988231Z","iopub.execute_input":"2023-12-02T07:48:02.988544Z","iopub.status.idle":"2023-12-02T07:48:03.017367Z","shell.execute_reply.started":"2023-12-02T07:48:02.988508Z","shell.execute_reply":"2023-12-02T07:48:03.016561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T07:48:03.018366Z","iopub.execute_input":"2023-12-02T07:48:03.018634Z","iopub.status.idle":"2023-12-02T07:48:03.034976Z","shell.execute_reply.started":"2023-12-02T07:48:03.018609Z","shell.execute_reply":"2023-12-02T07:48:03.033914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df['original_text']\ny = df['reference_summary']","metadata":{"id":"RnCjv6n7wVrN","execution":{"iopub.status.busy":"2023-12-02T07:48:03.036246Z","iopub.execute_input":"2023-12-02T07:48:03.036572Z","iopub.status.idle":"2023-12-02T07:48:03.042279Z","shell.execute_reply.started":"2023-12-02T07:48:03.036540Z","shell.execute_reply":"2023-12-02T07:48:03.041550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LEDDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels['input_ids'])","metadata":{"id":"YuCMAtjGeM86","execution":{"iopub.status.busy":"2023-12-02T07:48:03.043781Z","iopub.execute_input":"2023-12-02T07:48:03.044113Z","iopub.status.idle":"2023-12-02T07:48:03.051363Z","shell.execute_reply.started":"2023-12-02T07:48:03.044088Z","shell.execute_reply":"2023-12-02T07:48:03.050362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(model_name,\n                 train_texts, train_labels,\n                 test_texts, test_labels):\n  \"\"\"\n  Prepare input data for model fine-tuning\n  \"\"\"\n\n  tokenizer = AutoTokenizer.from_pretrained(model_name)\n  prepare_test = False if test_texts is None or test_labels is None else True\n\n  def tokenize_data(texts, labels):\n\n    encodings = tokenizer(texts, truncation=True, padding=True, max_length = 8192)\n    decodings = tokenizer(labels, truncation=True, padding=True, max_length = 512)\n    dataset_tokenized = LEDDataset(encodings, decodings)\n    return dataset_tokenized\n\n  train_dataset = tokenize_data(train_texts, train_labels)\n  test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n\n  return train_dataset, test_dataset, tokenizer","metadata":{"id":"NOdzySbseTAg","execution":{"iopub.status.busy":"2023-12-02T07:48:03.052682Z","iopub.execute_input":"2023-12-02T07:48:03.053027Z","iopub.status.idle":"2023-12-02T07:48:03.061198Z","shell.execute_reply.started":"2023-12-02T07:48:03.052994Z","shell.execute_reply":"2023-12-02T07:48:03.060287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_fine_tuning(model_name, tokenizer, train_dataset, test_dataset, freeze_encoder=False, output_dir='./results'):\n  \"\"\"\n  Prepare configurations and base model for fine-tuning\n  \"\"\"\n  torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n  model = LEDForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n\n  if test_dataset is not None:\n    training_args = TrainingArguments(\n      output_dir=output_dir,           # output directory\n      num_train_epochs=2,              # total number of training epochs\n      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n      per_device_eval_batch_size=1,    # batch size for evaluation, can increase if memory allows\n      save_steps=500,                  # number of updates steps before checkpoint saves\n      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n      evaluation_strategy='steps',     # evaluation strategy to adopt during training\n      eval_steps=100,                  # number of update steps before evaluation\n      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n      weight_decay=0.01,               # strength of weight decay\n      logging_dir='./logs',            # directory for storing logs\n      logging_steps=100,\n      report_to=\"wandb\",\n      run_name = \"longformer-billsum\"\n    )\n\n    trainer = Trainer(\n      model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n      args=training_args,                  # training arguments, defined above\n      train_dataset=train_dataset,         # training dataset\n      eval_dataset=test_dataset,           # evaluation dataset\n      tokenizer=tokenizer\n    )\n\n  else:\n    training_args = TrainingArguments(\n      output_dir=output_dir,           # output directory\n      num_train_epochs=2,              # total number of training epochs\n      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n      save_steps=500,                  # number of updates steps before checkpoint saves\n      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n      weight_decay=0.01,               # strength of weight decay\n      logging_dir='./logs',            # directory for storing logs\n      logging_steps=100,\n    )\n\n    trainer = Trainer(\n      model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n      args=training_args,                  # training arguments, defined above\n      train_dataset=train_dataset,         # training dataset\n      tokenizer=tokenizer\n    )\n\n  return trainer","metadata":{"id":"8sFuuoDheVvr","execution":{"iopub.status.busy":"2023-12-02T07:48:03.064256Z","iopub.execute_input":"2023-12-02T07:48:03.064581Z","iopub.status.idle":"2023-12-02T07:48:03.074641Z","shell.execute_reply.started":"2023-12-02T07:48:03.064545Z","shell.execute_reply":"2023-12-02T07:48:03.073730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n\ntrain_texts, train_labels = list(X_train), list(y_train)\ntest_texts, test_labels = list(X_test), list(y_test)","metadata":{"id":"1Qs6bhoOz8uV","execution":{"iopub.status.busy":"2023-12-02T07:48:03.078647Z","iopub.execute_input":"2023-12-02T07:48:03.078895Z","iopub.status.idle":"2023-12-02T07:48:03.088159Z","shell.execute_reply.started":"2023-12-02T07:48:03.078874Z","shell.execute_reply":"2023-12-02T07:48:03.087346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'Artifact-AI/led_large_16384_billsum_summarization'\n\ntrain_dataset,test_dataset, tokenizer = prepare_data(model_name, train_texts, train_labels,test_texts,test_labels)\ntrainer = prepare_fine_tuning(model_name, tokenizer, train_dataset,test_dataset)\n\ntrainer.train()","metadata":{"id":"PBpl_Dzoebmd","execution":{"iopub.status.busy":"2023-12-02T07:48:03.089335Z","iopub.execute_input":"2023-12-02T07:48:03.089664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate(test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nif not os.path.exists('./ouput_model/'):\n    os.makedirs('./ouput_model/')\ntrainer.model.save_pretrained(\"./ouput_model/\")","metadata":{"id":"IlT-HJrKefPH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Inference**","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"id":"S6RupAQGv2G4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = PretrainedConfig.from_json_file('./ouput_model/config.json')","metadata":{"id":"Vy4oVHjuwA5k","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LEDForConditionalGeneration.from_pretrained(\"./ouput_model/\").to(device)","metadata":{"id":"wjV9aYqwvsDL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize(text):\n  input_tokenized = tokenizer.encode(text, return_tensors='pt',max_length=8192,truncation=True).to(device)\n  summary_ids = model.generate(input_tokenized,\n                                  num_beams=9,\n                                  no_repeat_ngram_size=3,\n                                  length_penalty=2.0,\n                                  min_length=50,\n                                  max_length=512,\n                                  early_stopping=True)\n  summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n\n  return summary","metadata":{"id":"4eFewXp-vc6F","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = X_test.apply(lambda x: summarize(x))","metadata":{"id":"-W86Su68vqFv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary = pd.concat([y_test.to_frame(name=\"reference_summary\"), y_pred.to_frame(name=\"generated_summary\")], axis=1)","metadata":{"id":"Jj6hYeguyHsd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rouge = Rouge()","metadata":{"id":"QbsGPBCqyZoH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rouge.get_scores(summary['generated_summary'], summary['reference_summary'],avg=True)","metadata":{"id":"zTCns0rhybbx","trusted":true},"execution_count":null,"outputs":[]}]}